{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Redes neuronales artificiales_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from math import e "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visión general de la implemetación\n",
    "Se definen las clases **Neuron** y **ANN** las cuales representan de forma general a las neuronas y a la red neuronal a entrenear respectivamente. <br>\n",
    "Dados estos modelos, un objeto de tipo ANN se asocia a varios objetos de tipo Neuron. <br>\n",
    "Dicha asociación se da a través de dos listas de neuronas que contiene la clase ANN, una lista representando a la capa oculta y la restante a la capa de salida. <br>\n",
    "Adicionalmente el objeto ANN recibe como parámetro el número de neuronas que debe implementar en cada capa. <br>\n",
    "Dada esta arquitectura, solo es posible construir redes con una única capa oculta pero con capas de distinto tamaño. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Neuron\n",
    "***\n",
    "#### Métodos\n",
    "- **init(n_inputs)**: Inicializa n_inputs pesos de la neurona con valores entre -0.5 y 0.5 de forma aleatoria.\n",
    "- **compute_input(inputs)**: Calcula la combinación lineal entre los pesos y los valores de las inputs.\n",
    "- **apply_sigmoid(computed_value)**: Aplica la función de sigmoide a computed_value y almacena el valor de salida.\n",
    "- **calculate_output_neuron_error(expected)**: Aplica la formula de error para una neurona de la capa de salida y almacena el resultado. \n",
    "- **calculate_hidden_neuron_error(output_layer, index)**: Aplica la formula de error para una neurona de la capa de oculta y almacena el resultado.\n",
    "- **update_weights(rate, inputs)**: Actualiza todos los pesos de la neurona incluyendo el peso $w_{0}$ para el cual se asume una entrada de valor 1.\n",
    "\n",
    "#### Observaciones\n",
    "- Se asume que el valor $w_{0}$ es el último en la lista de pesos para mayor facilidad a la hora de implemetación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_inputs):\n",
    "        self.weights = [round(random.uniform(-0.5,0.5),5) for i in range(n_inputs)]\n",
    "        self.output = None\n",
    "        self.error = None\n",
    "\n",
    "    def compute_input(self, inputs):\n",
    "        result = self.weights[-1]\n",
    "        for i in range(len(self.weights)-1):\n",
    "            result += self.weights[i] * inputs[i]\n",
    "        return result\n",
    "    \n",
    "    def apply_sigmoid(self, computed_value):\n",
    "        self.output = 1 / (1 + e**(-computed_value)) \n",
    "        return self.output\n",
    "    \n",
    "    def calculate_output_neuron_error(self, expected):\n",
    "        self.error = self.output * (1.0 - self.output) * (expected - self.output) \n",
    "        return  self.error\n",
    "    \n",
    "    def calculate_hidden_neuron_error(self, output_layer, index):\n",
    "        self.error = 0.00000\n",
    "        for neuron in output_layer:\n",
    "            self.error += neuron.error * neuron.weights[index]\n",
    "        self.error *= self.output * (1.0 - self.output)\n",
    "        return self.error\n",
    "    \n",
    "    def update_weights(self, rate, inputs):\n",
    "        for i in range(len(self.inputs)):\n",
    "            self.weights[i] += rate * self.error * inputs[i]\n",
    "        self.weights[-1] += rate * self.error  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ANN\n",
    "***\n",
    "#### Métodos\n",
    "- **init(n_inputs, n_hidden, n_outputs)**: Inicializa las neuronas de la capa oculta y la capa de salida. Para la capa oculta se crean n_hidden neuronas cada una de las cuales tiene (n_inputs + 1) pesos, uno por cada columna en el conjunto de datos más el adicional por el peso $w_{0}$. Adicionalmente se crean n_outputs neuronas para la capa de salida, cada una con (n_hidden + 1) pesos. Esto significa que cada neurona en la capa de salida se conecta con cada neurona de la capa oculta.\n",
    "- **forward_propagate(instance)**: Recibe en instance una instancia a clasificar, procesa la misma con cada neurona de la capa oculta, luego cada salida generada por las neuronas de la capa oculta son procesadas por cada una de las neuronas de la capa de salida, devolviendo finalmente el resultado de la clasificación.\n",
    "- **update_weights(instance)**: Actualiza todos los pesos presentes en la red. Recibe la última instancia procesada como parámetro ya que son las inputs necesarias para actualizar pesos de la capa oculta."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 4,
>>>>>>> fixing
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        self.hidden_layer = [Neuron(n_inputs + 1) for i in range(n_hidden)]\n",
    "        self.output_layer = [Neuron(n_hidden + 1) for i in range(n_outputs)]\n",
    "\n",
    "    def forward_propagate(self, instance):\n",
    "        \n",
    "        inputs = instance\n",
    "        hidden_layer_outputs = []\n",
    "        for neuron in self.hidden_layer:\n",
    "            computed_input = neuron.compute_input(inputs)\n",
    "            neuron_output = neuron.apply_sigmoid(computed_input)\n",
    "            hidden_layer_outputs.append(neuron_output)\n",
    "        \n",
    "        inputs = hidden_layer_outputs\n",
    "        final_outputs = []\n",
    "        for neuron in self.output_layer:\n",
    "            computed_input = neuron.compute_input(inputs)\n",
    "            neuron_output = neuron.apply_sigmoid(computed_input)\n",
    "            final_outputs.append(neuron_output)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    def update_weights(self, instance):\n",
    "        \n",
    "        output_layer_inputs = []\n",
    "        for neuron in self.hidden_layer:\n",
    "            neuron.update_weights(rate, instance)\n",
    "            output_layer_inputs.append(neuron.output)\n",
    "        \n",
    "        for neuron in self.output_layer:\n",
    "            neuron.update_weights(rate, output_layer_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte a) <br>\n",
    "### Algoritmo Backpropagation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 12,
>>>>>>> fixing
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation(n_inputs, n_hidden, n_outputs, max_iter, data_set):\n",
    "    \n",
    "    # Crea la red neuronal artificial.     \n",
    "    neural_network = ANN(n_inputs, n_hidden, n_outputs)\n",
    "    \n",
    "    for iter in range (max_iter):\n",
    "        \n",
    "        # Se recorre el conjunto de entrenamiento.         \n",
    "        for (instance, expected) in data_set:\n",
    "            \n",
    "            # Se clasifica la instancia.             \n",
    "            output = neural_network.forward_propagate(instance)\n",
    "            \n",
    "            # Se recorren las neuronas de la capa de salida.             \n",
    "            for index, neuron in enumerate(ANN.output_layer):\n",
    "                # Se calcula y almacena el error para cada neurona.               \n",
    "                neuron.calculate_output_neuron_error(expected[index])\n",
    "                                     \n",
    "            # Se recorren las neuronas de la capa oculta.\n",
    "            for index, neuron in enumerate(ANN.hidden_layer):\n",
    "                # Se calcula y almacena el error para cada neurona.               \n",
    "                neuron.calculate_hidden_neuron_error(ANN.output_layer, index)\n",
    "\n",
    "            # Se actualizan todos los pesos de la red.\n",
    "            neural_network.update_weights(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte b)\n",
    "\n",
    "Se definen las funciones de la letra a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*x*x - x*x + 1\n",
    "\n",
    "def g(x,y):\n",
    "    return 1 - x*2 - y*2\n",
    "    \n",
    "def h(x,y):\n",
    "    return x + y\n",
    "\n",
    "training_set = [([x],f(x))for x in np.random.uniform(-1,1,40)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ANN' has no attribute 'output_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7c8db0510203>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbackpropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-d20529a957ea>\u001b[0m in \u001b[0;36mbackpropagation\u001b[1;34m(n_inputs, n_hidden, n_outputs, max_iter, data_set)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# Se recorren las neuronas de la capa de salida.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneuron\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mANN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;31m# Se calcula y almacena el error para cada neurona.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_output_neuron_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ANN' has no attribute 'output_layer'"
     ]
    }
   ],
   "source": [
    "backpropagation(1,3,1,10,training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
